{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Project Title\n",
    "### Data Engineering Capstone Project\n",
    "\n",
    "#### Project Summary\n",
    "--describe your project at a high level--\n",
    "\n",
    "The project follows the follow steps:\n",
    "* Step 1: Scope the Project and Gather Data\n",
    "* Step 2: Explore and Assess the Data\n",
    "* Step 3: Define the Data Model\n",
    "* Step 4: Run ETL to Model the Data\n",
    "* Step 5: Complete Project Write Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Do all imports and installs here\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "from pyspark.sql import SparkSession\n",
    "import os\n",
    "import configparser\n",
    "from insert_data import insert_fact, insert_dim_imm_per, insert_dim_imm_air, insert_dim_demo_info, insert_dim_demo_stat, insert_dim_temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 1: Scope the Project and Gather Data\n",
    "\n",
    "#### Scope \n",
    "Explain what you plan to do in the project in more detail. What data do you use? What is your end solution look like? What tools did you use? etc>\n",
    "\n",
    "The purpose of this project is to see the connection between the temperature of the cities that people immigrate to. We could check the preferred destination cities for immigrants based on the immigration year as well. This data will be used for a BI app.\n",
    "\n",
    "__Data Used:__\n",
    "- I94 Immigration Data\n",
    "- Temperature Data\n",
    "- Demographics Data\n",
    "\n",
    "__Tools Used:__\n",
    "- AWS\n",
    "    - S3\n",
    "    - Redshift\n",
    "- Python\n",
    "    - PySpark\n",
    "- Airflow for Pipeline\n",
    "\n",
    "#### Describe and Gather Data \n",
    "Describe the data sets you're using. Where did it come from? What type of information is included? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### I94 Immigration Data\n",
    "This data comes from [National Travel and Trourism Office(NTTO)](https://www.trade.gov/national-travel-and-tourism-office). The subject of the data is the immigrants going to the U.S. and the information is gives are where they come from, birth year, gender, visa type, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Read in the data here\n",
    "fname = '../../data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat'\n",
    "df = pd.read_sas(fname, 'sas7bdat', encoding=\"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>i94port</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>depdate</th>\n",
       "      <th>...</th>\n",
       "      <th>entdepu</th>\n",
       "      <th>matflag</th>\n",
       "      <th>biryear</th>\n",
       "      <th>dtaddto</th>\n",
       "      <th>gender</th>\n",
       "      <th>insnum</th>\n",
       "      <th>airline</th>\n",
       "      <th>admnum</th>\n",
       "      <th>fltno</th>\n",
       "      <th>visatype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>692.0</td>\n",
       "      <td>692.0</td>\n",
       "      <td>XXX</td>\n",
       "      <td>20573.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>U</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1979.0</td>\n",
       "      <td>10282016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.897628e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>276.0</td>\n",
       "      <td>ATL</td>\n",
       "      <td>20551.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>D/S</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.736796e+09</td>\n",
       "      <td>00296</td>\n",
       "      <td>F1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>WAS</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MI</td>\n",
       "      <td>20691.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1961.0</td>\n",
       "      <td>09302016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OS</td>\n",
       "      <td>6.666432e+08</td>\n",
       "      <td>93</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MA</td>\n",
       "      <td>20567.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1988.0</td>\n",
       "      <td>09302016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AA</td>\n",
       "      <td>9.246846e+10</td>\n",
       "      <td>00199</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MA</td>\n",
       "      <td>20567.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>09302016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AA</td>\n",
       "      <td>9.246846e+10</td>\n",
       "      <td>00199</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   cicid   i94yr  i94mon  i94cit  i94res i94port  arrdate  i94mode i94addr  \\\n",
       "0    6.0  2016.0     4.0   692.0   692.0     XXX  20573.0      NaN     NaN   \n",
       "1    7.0  2016.0     4.0   254.0   276.0     ATL  20551.0      1.0      AL   \n",
       "2   15.0  2016.0     4.0   101.0   101.0     WAS  20545.0      1.0      MI   \n",
       "3   16.0  2016.0     4.0   101.0   101.0     NYC  20545.0      1.0      MA   \n",
       "4   17.0  2016.0     4.0   101.0   101.0     NYC  20545.0      1.0      MA   \n",
       "\n",
       "   depdate   ...     entdepu  matflag  biryear   dtaddto gender insnum  \\\n",
       "0      NaN   ...           U      NaN   1979.0  10282016    NaN    NaN   \n",
       "1      NaN   ...           Y      NaN   1991.0       D/S      M    NaN   \n",
       "2  20691.0   ...         NaN        M   1961.0  09302016      M    NaN   \n",
       "3  20567.0   ...         NaN        M   1988.0  09302016    NaN    NaN   \n",
       "4  20567.0   ...         NaN        M   2012.0  09302016    NaN    NaN   \n",
       "\n",
       "  airline        admnum  fltno visatype  \n",
       "0     NaN  1.897628e+09    NaN       B2  \n",
       "1     NaN  3.736796e+09  00296       F1  \n",
       "2      OS  6.666432e+08     93       B2  \n",
       "3      AA  9.246846e+10  00199       B2  \n",
       "4      AA  9.246846e+10  00199       B2  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['cicid', 'i94yr', 'i94mon', 'i94cit', 'i94res', 'i94port', 'arrdate',\n",
       "       'i94mode', 'i94addr', 'depdate', 'i94bir', 'i94visa', 'count',\n",
       "       'dtadfile', 'visapost', 'occup', 'entdepa', 'entdepd', 'entdepu',\n",
       "       'matflag', 'biryear', 'dtaddto', 'gender', 'insnum', 'airline',\n",
       "       'admnum', 'fltno', 'visatype'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cic_id</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>dep_city</th>\n",
       "      <th>arrival_date</th>\n",
       "      <th>dep_date</th>\n",
       "      <th>travel_code</th>\n",
       "      <th>visa</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>XXX</td>\n",
       "      <td>20573.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>ATL</td>\n",
       "      <td>20551.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>WAS</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>20691.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>20567.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>20567.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cic_id    year  month dep_city  arrival_date  dep_date  travel_code  visa  \\\n",
       "0     6.0  2016.0    4.0      XXX       20573.0       NaN          NaN   2.0   \n",
       "1     7.0  2016.0    4.0      ATL       20551.0       NaN          1.0   3.0   \n",
       "2    15.0  2016.0    4.0      WAS       20545.0   20691.0          1.0   2.0   \n",
       "3    16.0  2016.0    4.0      NYC       20545.0   20567.0          1.0   2.0   \n",
       "4    17.0  2016.0    4.0      NYC       20545.0   20567.0          1.0   2.0   \n",
       "\n",
       "         country  \n",
       "0  United States  \n",
       "1  United States  \n",
       "2  United States  \n",
       "3  United States  \n",
       "4  United States  "
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fact_immigration = df[['cicid', 'i94yr', 'i94mon', 'i94port', 'arrdate', 'depdate', 'i94mode', 'i94visa']]\n",
    "fact_immigration.columns = ['cic_id', 'year', 'month', 'dep_city', 'arrival_date', 'dep_date', 'travel_code', 'visa']\n",
    "fact_immigration['country'] = 'United States'\n",
    "fact_immigration.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cic_id</th>\n",
       "      <th>citizen_country</th>\n",
       "      <th>resident_country</th>\n",
       "      <th>birthyear</th>\n",
       "      <th>gender</th>\n",
       "      <th>ins_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.0</td>\n",
       "      <td>692.0</td>\n",
       "      <td>692.0</td>\n",
       "      <td>1979.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>276.0</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>1961.0</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>1988.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cic_id  citizen_country  resident_country  birthyear gender ins_number\n",
       "0     6.0            692.0             692.0     1979.0    NaN        NaN\n",
       "1     7.0            254.0             276.0     1991.0      M        NaN\n",
       "2    15.0            101.0             101.0     1961.0      M        NaN\n",
       "3    16.0            101.0             101.0     1988.0    NaN        NaN\n",
       "4    17.0            101.0             101.0     2012.0    NaN        NaN"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim_immigration_personal = df[['cicid', 'i94cit', 'i94res', 'biryear', 'gender', 'insnum']]\n",
    "dim_immigration_personal.columns = ['cic_id', 'citizen_country', 'resident_country', 'birthyear', 'gender', 'ins_number']\n",
    "dim_immigration_personal.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cic_id</th>\n",
       "      <th>airline</th>\n",
       "      <th>admin_number</th>\n",
       "      <th>flight_number</th>\n",
       "      <th>visa</th>\n",
       "      <th>visa_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.897628e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.736796e+09</td>\n",
       "      <td>00296</td>\n",
       "      <td>3.0</td>\n",
       "      <td>F1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15.0</td>\n",
       "      <td>OS</td>\n",
       "      <td>6.666432e+08</td>\n",
       "      <td>93</td>\n",
       "      <td>2.0</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>AA</td>\n",
       "      <td>9.246846e+10</td>\n",
       "      <td>00199</td>\n",
       "      <td>2.0</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>AA</td>\n",
       "      <td>9.246846e+10</td>\n",
       "      <td>00199</td>\n",
       "      <td>2.0</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cic_id airline  admin_number flight_number  visa visa_type\n",
       "0     6.0     NaN  1.897628e+09           NaN   2.0        B2\n",
       "1     7.0     NaN  3.736796e+09         00296   3.0        F1\n",
       "2    15.0      OS  6.666432e+08            93   2.0        B2\n",
       "3    16.0      AA  9.246846e+10         00199   2.0        B2\n",
       "4    17.0      AA  9.246846e+10         00199   2.0        B2"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim_immigration_air = df[['cicid', 'airline', 'admnum', 'fltno', 'i94visa', 'visatype']]\n",
    "dim_immigration_air.columns = ['cic_id', 'airline', 'admin_number', 'flight_number', 'visa', 'visa_type']\n",
    "dim_immigration_air.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.\\\n",
    "config(\"spark.jars.repositories\", \"https://repos.spark-packages.org/\").\\\n",
    "config(\"spark.jars.packages\", \"saurfang:spark-sas7bdat:2.0.0-s_2.11\").\\\n",
    "enableHiveSupport().getOrCreate()\n",
    "\n",
    "df_spark = spark.read.format('com.github.saurfang.sas.spark').load('../../data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "'path file:/home/workspace/sas_data already exists.;'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/opt/spark-2.4.3-bin-hadoop2.7/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark-2.4.3-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o47.parquet.\n: org.apache.spark.sql.AnalysisException: path file:/home/workspace/sas_data already exists.;\n\tat org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.run(InsertIntoHadoopFsRelationCommand.scala:114)\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult$lzycompute(commands.scala:104)\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult(commands.scala:102)\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.doExecute(commands.scala:122)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.QueryExecution.toRdd$lzycompute(QueryExecution.scala:80)\n\tat org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:80)\n\tat org.apache.spark.sql.DataFrameWriter$$anonfun$runCommand$1.apply(DataFrameWriter.scala:676)\n\tat org.apache.spark.sql.DataFrameWriter$$anonfun$runCommand$1.apply(DataFrameWriter.scala:676)\n\tat org.apache.spark.sql.execution.SQLExecution$$anonfun$withNewExecutionId$1.apply(SQLExecution.scala:78)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:125)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:73)\n\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:676)\n\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:285)\n\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:271)\n\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:229)\n\tat org.apache.spark.sql.DataFrameWriter.parquet(DataFrameWriter.scala:566)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-9814a8024ab4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#write to parquet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf_spark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparquet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"sas_data\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdf_spark\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparquet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"sas_data\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark-2.4.3-bin-hadoop2.7/python/pyspark/sql/readwriter.py\u001b[0m in \u001b[0;36mparquet\u001b[0;34m(self, path, mode, partitionBy, compression)\u001b[0m\n\u001b[1;32m    837\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartitionBy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpartitionBy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    838\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_opts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompression\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 839\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jwrite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparquet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    840\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    841\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0msince\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark-2.4.3-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1255\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1257\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark-2.4.3-bin-hadoop2.7/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     67\u001b[0m                                              e.java_exception.getStackTrace()))\n\u001b[1;32m     68\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'org.apache.spark.sql.AnalysisException: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mAnalysisException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'org.apache.spark.sql.catalyst.analysis'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mAnalysisException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: 'path file:/home/workspace/sas_data already exists.;'"
     ]
    }
   ],
   "source": [
    "#write to parquet\n",
    "df_spark.write.parquet(\"sas_data\")\n",
    "df_spark=spark.read.parquet(\"sas_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Temperature Data\n",
    "This data comes from [Kaggle](https://www.kaggle.com/berkeleyearth/climate-change-earth-surface-temperature-data), and it shows the temperature in different cities around the world. It's recorded monthly, and the values are the average temperature of that month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "fname = '../../data2/GlobalLandTemperaturesByCity.csv'\n",
    "df_temp = pd.read_csv(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>AverageTemperature</th>\n",
       "      <th>AverageTemperatureUncertainty</th>\n",
       "      <th>City</th>\n",
       "      <th>Country</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1743-11-01</td>\n",
       "      <td>6.068</td>\n",
       "      <td>1.737</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1743-12-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1744-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1744-02-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1744-03-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           dt  AverageTemperature  AverageTemperatureUncertainty   City  \\\n",
       "0  1743-11-01               6.068                          1.737  Århus   \n",
       "1  1743-12-01                 NaN                            NaN  Århus   \n",
       "2  1744-01-01                 NaN                            NaN  Århus   \n",
       "3  1744-02-01                 NaN                            NaN  Århus   \n",
       "4  1744-03-01                 NaN                            NaN  Århus   \n",
       "\n",
       "   Country Latitude Longitude  \n",
       "0  Denmark   57.05N    10.33E  \n",
       "1  Denmark   57.05N    10.33E  \n",
       "2  Denmark   57.05N    10.33E  \n",
       "3  Denmark   57.05N    10.33E  \n",
       "4  Denmark   57.05N    10.33E  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>avg_temp</th>\n",
       "      <th>avg_temp_uncertainty</th>\n",
       "      <th>city</th>\n",
       "      <th>country</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47555</th>\n",
       "      <td>1820-01-01</td>\n",
       "      <td>2.101</td>\n",
       "      <td>3.217</td>\n",
       "      <td>Abilene</td>\n",
       "      <td>United States</td>\n",
       "      <td>32.95N</td>\n",
       "      <td>100.53W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47556</th>\n",
       "      <td>1820-02-01</td>\n",
       "      <td>6.926</td>\n",
       "      <td>2.853</td>\n",
       "      <td>Abilene</td>\n",
       "      <td>United States</td>\n",
       "      <td>32.95N</td>\n",
       "      <td>100.53W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47557</th>\n",
       "      <td>1820-03-01</td>\n",
       "      <td>10.767</td>\n",
       "      <td>2.395</td>\n",
       "      <td>Abilene</td>\n",
       "      <td>United States</td>\n",
       "      <td>32.95N</td>\n",
       "      <td>100.53W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47558</th>\n",
       "      <td>1820-04-01</td>\n",
       "      <td>17.989</td>\n",
       "      <td>2.202</td>\n",
       "      <td>Abilene</td>\n",
       "      <td>United States</td>\n",
       "      <td>32.95N</td>\n",
       "      <td>100.53W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47559</th>\n",
       "      <td>1820-05-01</td>\n",
       "      <td>21.809</td>\n",
       "      <td>2.036</td>\n",
       "      <td>Abilene</td>\n",
       "      <td>United States</td>\n",
       "      <td>32.95N</td>\n",
       "      <td>100.53W</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               dt  avg_temp  avg_temp_uncertainty     city        country  \\\n",
       "47555  1820-01-01     2.101                 3.217  Abilene  United States   \n",
       "47556  1820-02-01     6.926                 2.853  Abilene  United States   \n",
       "47557  1820-03-01    10.767                 2.395  Abilene  United States   \n",
       "47558  1820-04-01    17.989                 2.202  Abilene  United States   \n",
       "47559  1820-05-01    21.809                 2.036  Abilene  United States   \n",
       "\n",
       "      latitude longitude  \n",
       "47555   32.95N   100.53W  \n",
       "47556   32.95N   100.53W  \n",
       "47557   32.95N   100.53W  \n",
       "47558   32.95N   100.53W  \n",
       "47559   32.95N   100.53W  "
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temp_us = df_temp[df_temp['Country'] == 'United States']\n",
    "df_temp_us.columns = ['dt', 'avg_temp', 'avg_temp_uncertainty', 'city', 'country', 'latitude', 'longitude']\n",
    "df_temp_us.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>avg_temp</th>\n",
       "      <th>avg_temp_uncertainty</th>\n",
       "      <th>city</th>\n",
       "      <th>country</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47555</th>\n",
       "      <td>1820-01-01</td>\n",
       "      <td>2.101</td>\n",
       "      <td>3.217</td>\n",
       "      <td>Abilene</td>\n",
       "      <td>United States</td>\n",
       "      <td>32.95N</td>\n",
       "      <td>100.53W</td>\n",
       "      <td>1</td>\n",
       "      <td>1820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47556</th>\n",
       "      <td>1820-02-01</td>\n",
       "      <td>6.926</td>\n",
       "      <td>2.853</td>\n",
       "      <td>Abilene</td>\n",
       "      <td>United States</td>\n",
       "      <td>32.95N</td>\n",
       "      <td>100.53W</td>\n",
       "      <td>2</td>\n",
       "      <td>1820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47557</th>\n",
       "      <td>1820-03-01</td>\n",
       "      <td>10.767</td>\n",
       "      <td>2.395</td>\n",
       "      <td>Abilene</td>\n",
       "      <td>United States</td>\n",
       "      <td>32.95N</td>\n",
       "      <td>100.53W</td>\n",
       "      <td>3</td>\n",
       "      <td>1820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47558</th>\n",
       "      <td>1820-04-01</td>\n",
       "      <td>17.989</td>\n",
       "      <td>2.202</td>\n",
       "      <td>Abilene</td>\n",
       "      <td>United States</td>\n",
       "      <td>32.95N</td>\n",
       "      <td>100.53W</td>\n",
       "      <td>4</td>\n",
       "      <td>1820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47559</th>\n",
       "      <td>1820-05-01</td>\n",
       "      <td>21.809</td>\n",
       "      <td>2.036</td>\n",
       "      <td>Abilene</td>\n",
       "      <td>United States</td>\n",
       "      <td>32.95N</td>\n",
       "      <td>100.53W</td>\n",
       "      <td>5</td>\n",
       "      <td>1820</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              dt  avg_temp  avg_temp_uncertainty     city        country  \\\n",
       "47555 1820-01-01     2.101                 3.217  Abilene  United States   \n",
       "47556 1820-02-01     6.926                 2.853  Abilene  United States   \n",
       "47557 1820-03-01    10.767                 2.395  Abilene  United States   \n",
       "47558 1820-04-01    17.989                 2.202  Abilene  United States   \n",
       "47559 1820-05-01    21.809                 2.036  Abilene  United States   \n",
       "\n",
       "      latitude longitude  month  year  \n",
       "47555   32.95N   100.53W      1  1820  \n",
       "47556   32.95N   100.53W      2  1820  \n",
       "47557   32.95N   100.53W      3  1820  \n",
       "47558   32.95N   100.53W      4  1820  \n",
       "47559   32.95N   100.53W      5  1820  "
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temp_us['dt'] = pd.to_datetime(df_temp_us['dt'])\n",
    "df_temp_us['month'] = pd.DatetimeIndex(df_temp_us['dt']).month\n",
    "df_temp_us['year'] = pd.DatetimeIndex(df_temp_us['dt']).year\n",
    "df_temp_us.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### US Cities Demographics Data\n",
    "This data comes from [OpenSoft](https://public.opendatasoft.com/explore/dataset/us-cities-demographics/export/), and it shows the demographics of the cities in the U.S. including the population, median age, the state the city belongs to, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "fname = './us-cities-demographics.csv'\n",
    "df_demo = pd.read_csv(fname, delimiter=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Median Age</th>\n",
       "      <th>Male Population</th>\n",
       "      <th>Female Population</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Number of Veterans</th>\n",
       "      <th>Foreign-born</th>\n",
       "      <th>Average Household Size</th>\n",
       "      <th>State Code</th>\n",
       "      <th>Race</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Silver Spring</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>33.8</td>\n",
       "      <td>40601.0</td>\n",
       "      <td>41862.0</td>\n",
       "      <td>82463</td>\n",
       "      <td>1562.0</td>\n",
       "      <td>30908.0</td>\n",
       "      <td>2.60</td>\n",
       "      <td>MD</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>25924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Quincy</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>41.0</td>\n",
       "      <td>44129.0</td>\n",
       "      <td>49500.0</td>\n",
       "      <td>93629</td>\n",
       "      <td>4147.0</td>\n",
       "      <td>32935.0</td>\n",
       "      <td>2.39</td>\n",
       "      <td>MA</td>\n",
       "      <td>White</td>\n",
       "      <td>58723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hoover</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>38.5</td>\n",
       "      <td>38040.0</td>\n",
       "      <td>46799.0</td>\n",
       "      <td>84839</td>\n",
       "      <td>4819.0</td>\n",
       "      <td>8229.0</td>\n",
       "      <td>2.58</td>\n",
       "      <td>AL</td>\n",
       "      <td>Asian</td>\n",
       "      <td>4759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rancho Cucamonga</td>\n",
       "      <td>California</td>\n",
       "      <td>34.5</td>\n",
       "      <td>88127.0</td>\n",
       "      <td>87105.0</td>\n",
       "      <td>175232</td>\n",
       "      <td>5821.0</td>\n",
       "      <td>33878.0</td>\n",
       "      <td>3.18</td>\n",
       "      <td>CA</td>\n",
       "      <td>Black or African-American</td>\n",
       "      <td>24437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Newark</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>34.6</td>\n",
       "      <td>138040.0</td>\n",
       "      <td>143873.0</td>\n",
       "      <td>281913</td>\n",
       "      <td>5829.0</td>\n",
       "      <td>86253.0</td>\n",
       "      <td>2.73</td>\n",
       "      <td>NJ</td>\n",
       "      <td>White</td>\n",
       "      <td>76402</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               City          State  Median Age  Male Population  \\\n",
       "0     Silver Spring       Maryland        33.8          40601.0   \n",
       "1            Quincy  Massachusetts        41.0          44129.0   \n",
       "2            Hoover        Alabama        38.5          38040.0   \n",
       "3  Rancho Cucamonga     California        34.5          88127.0   \n",
       "4            Newark     New Jersey        34.6         138040.0   \n",
       "\n",
       "   Female Population  Total Population  Number of Veterans  Foreign-born  \\\n",
       "0            41862.0             82463              1562.0       30908.0   \n",
       "1            49500.0             93629              4147.0       32935.0   \n",
       "2            46799.0             84839              4819.0        8229.0   \n",
       "3            87105.0            175232              5821.0       33878.0   \n",
       "4           143873.0            281913              5829.0       86253.0   \n",
       "\n",
       "   Average Household Size State Code                       Race  Count  \n",
       "0                    2.60         MD         Hispanic or Latino  25924  \n",
       "1                    2.39         MA                      White  58723  \n",
       "2                    2.58         AL                      Asian   4759  \n",
       "3                    3.18         CA  Black or African-American  24437  \n",
       "4                    2.73         NJ                      White  76402  "
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_demo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>m_population</th>\n",
       "      <th>f_population</th>\n",
       "      <th>total_population</th>\n",
       "      <th>num_of_veterans</th>\n",
       "      <th>foreign_born</th>\n",
       "      <th>state_code</th>\n",
       "      <th>race</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Silver Spring</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>40601.0</td>\n",
       "      <td>41862.0</td>\n",
       "      <td>82463</td>\n",
       "      <td>1562.0</td>\n",
       "      <td>30908.0</td>\n",
       "      <td>MD</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Quincy</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>44129.0</td>\n",
       "      <td>49500.0</td>\n",
       "      <td>93629</td>\n",
       "      <td>4147.0</td>\n",
       "      <td>32935.0</td>\n",
       "      <td>MA</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hoover</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>38040.0</td>\n",
       "      <td>46799.0</td>\n",
       "      <td>84839</td>\n",
       "      <td>4819.0</td>\n",
       "      <td>8229.0</td>\n",
       "      <td>AL</td>\n",
       "      <td>Asian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rancho Cucamonga</td>\n",
       "      <td>California</td>\n",
       "      <td>88127.0</td>\n",
       "      <td>87105.0</td>\n",
       "      <td>175232</td>\n",
       "      <td>5821.0</td>\n",
       "      <td>33878.0</td>\n",
       "      <td>CA</td>\n",
       "      <td>Black or African-American</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Newark</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>138040.0</td>\n",
       "      <td>143873.0</td>\n",
       "      <td>281913</td>\n",
       "      <td>5829.0</td>\n",
       "      <td>86253.0</td>\n",
       "      <td>NJ</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               city          state  m_population  f_population  \\\n",
       "0     Silver Spring       Maryland       40601.0       41862.0   \n",
       "1            Quincy  Massachusetts       44129.0       49500.0   \n",
       "2            Hoover        Alabama       38040.0       46799.0   \n",
       "3  Rancho Cucamonga     California       88127.0       87105.0   \n",
       "4            Newark     New Jersey      138040.0      143873.0   \n",
       "\n",
       "   total_population  num_of_veterans  foreign_born state_code  \\\n",
       "0             82463           1562.0       30908.0         MD   \n",
       "1             93629           4147.0       32935.0         MA   \n",
       "2             84839           4819.0        8229.0         AL   \n",
       "3            175232           5821.0       33878.0         CA   \n",
       "4            281913           5829.0       86253.0         NJ   \n",
       "\n",
       "                        race  \n",
       "0         Hispanic or Latino  \n",
       "1                      White  \n",
       "2                      Asian  \n",
       "3  Black or African-American  \n",
       "4                      White  "
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_demo_info = df_demo[['City', 'State', 'Male Population', 'Female Population', 'Total Population', 'Number of Veterans', 'Foreign-born', 'State Code', 'Race']]\n",
    "df_demo_info.columns = ['city', 'state', 'm_population', 'f_population', 'total_population', 'num_of_veterans', 'foreign_born', 'state_code', 'race']\n",
    "df_demo_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>median_age</th>\n",
       "      <th>avg_household_size</th>\n",
       "      <th>state_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Silver Spring</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>33.8</td>\n",
       "      <td>2.60</td>\n",
       "      <td>MD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Quincy</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>41.0</td>\n",
       "      <td>2.39</td>\n",
       "      <td>MA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hoover</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>38.5</td>\n",
       "      <td>2.58</td>\n",
       "      <td>AL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rancho Cucamonga</td>\n",
       "      <td>California</td>\n",
       "      <td>34.5</td>\n",
       "      <td>3.18</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Newark</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>34.6</td>\n",
       "      <td>2.73</td>\n",
       "      <td>NJ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               city          state  median_age  avg_household_size state_code\n",
       "0     Silver Spring       Maryland        33.8                2.60         MD\n",
       "1            Quincy  Massachusetts        41.0                2.39         MA\n",
       "2            Hoover        Alabama        38.5                2.58         AL\n",
       "3  Rancho Cucamonga     California        34.5                3.18         CA\n",
       "4            Newark     New Jersey        34.6                2.73         NJ"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_demo_stat = df_demo[['City', 'State', 'Median Age', 'Average Household Size', 'State Code']]\n",
    "df_demo_stat.columns = ['city', 'state', 'median_age', 'avg_household_size', 'state_code']\n",
    "df_demo_stat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 2: Explore and Assess the Data\n",
    "#### Explore the Data \n",
    "Identify data quality issues, like missing values, duplicate data, etc.\n",
    "\n",
    "#### Cleaning Steps\n",
    "Document steps necessary to clean the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Converting floats into datetime format for fact_immigration table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cic_id          float64\n",
       "year            float64\n",
       "month           float64\n",
       "dep_city         object\n",
       "arrival_date    float64\n",
       "dep_date        float64\n",
       "travel_code     float64\n",
       "visa            float64\n",
       "country          object\n",
       "dtype: object"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fact_immigration.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cic_id</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>dep_city</th>\n",
       "      <th>arrival_date</th>\n",
       "      <th>dep_date</th>\n",
       "      <th>travel_code</th>\n",
       "      <th>visa</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>XXX</td>\n",
       "      <td>2016-04-29</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>ATL</td>\n",
       "      <td>2016-04-07</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>WAS</td>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>2016-08-25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>2016-04-23</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>2016-04-23</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cic_id    year  month dep_city arrival_date   dep_date  travel_code  visa  \\\n",
       "0     6.0  2016.0    4.0      XXX   2016-04-29        NaT          NaN   2.0   \n",
       "1     7.0  2016.0    4.0      ATL   2016-04-07        NaT          1.0   3.0   \n",
       "2    15.0  2016.0    4.0      WAS   2016-04-01 2016-08-25          1.0   2.0   \n",
       "3    16.0  2016.0    4.0      NYC   2016-04-01 2016-04-23          1.0   2.0   \n",
       "4    17.0  2016.0    4.0      NYC   2016-04-01 2016-04-23          1.0   2.0   \n",
       "\n",
       "         country  \n",
       "0  United States  \n",
       "1  United States  \n",
       "2  United States  \n",
       "3  United States  \n",
       "4  United States  "
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fact_immigration['arrival_date'] = pd.to_datetime(fact_immigration['arrival_date'], unit='D',\n",
    "               origin=pd.Timestamp('1960-01-01'))\n",
    "fact_immigration['dep_date'] = pd.to_datetime(fact_immigration['dep_date'], unit='D',\n",
    "               origin=pd.Timestamp('1960-01-01'))\n",
    "fact_immigration.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "fact_immigration = fact_immigration[pd.notnull(fact_immigration['arrival_date'])]\n",
    "fact_immigration = fact_immigration[pd.notnull(fact_immigration['dep_date'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Dropping the non-integer rows in flight_number column in the dim_immigration_air table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cic_id           float64\n",
       "airline           object\n",
       "admin_number     float64\n",
       "flight_number     object\n",
       "visa             float64\n",
       "visa_type         object\n",
       "dtype: object"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim_immigration_air.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cic_id</th>\n",
       "      <th>airline</th>\n",
       "      <th>admin_number</th>\n",
       "      <th>flight_number</th>\n",
       "      <th>visa</th>\n",
       "      <th>visa_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3096283</th>\n",
       "      <td>5200122.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.466694e+10</td>\n",
       "      <td>LAND</td>\n",
       "      <td>2.0</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3096284</th>\n",
       "      <td>5200121.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.466708e+10</td>\n",
       "      <td>LAND</td>\n",
       "      <td>2.0</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3096285</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3096286</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3096287</th>\n",
       "      <td>2303672.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.870831e+08</td>\n",
       "      <td>LAND</td>\n",
       "      <td>1.0</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3096288</th>\n",
       "      <td>625288.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.266689e+10</td>\n",
       "      <td>LAND</td>\n",
       "      <td>1.0</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3096289</th>\n",
       "      <td>2873230.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.806588e+10</td>\n",
       "      <td>LAND</td>\n",
       "      <td>2.0</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3096290</th>\n",
       "      <td>2873231.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.806625e+10</td>\n",
       "      <td>LAND</td>\n",
       "      <td>2.0</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3096291</th>\n",
       "      <td>2873232.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.806640e+10</td>\n",
       "      <td>LAND</td>\n",
       "      <td>2.0</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3096292</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3096293</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3096294</th>\n",
       "      <td>218224.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.251075e+10</td>\n",
       "      <td>LAND</td>\n",
       "      <td>2.0</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3096295</th>\n",
       "      <td>2873233.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.356363e+10</td>\n",
       "      <td>LAND</td>\n",
       "      <td>2.0</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3096296</th>\n",
       "      <td>2873234.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.356366e+10</td>\n",
       "      <td>LAND</td>\n",
       "      <td>2.0</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3096297</th>\n",
       "      <td>3298796.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.379549e+10</td>\n",
       "      <td>LAND</td>\n",
       "      <td>1.0</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3096298</th>\n",
       "      <td>4249463.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.428408e+10</td>\n",
       "      <td>LAND</td>\n",
       "      <td>1.0</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3096299</th>\n",
       "      <td>1153287.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.878366e+08</td>\n",
       "      <td>LAND</td>\n",
       "      <td>2.0</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3096300</th>\n",
       "      <td>1153288.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.880218e+08</td>\n",
       "      <td>LAND</td>\n",
       "      <td>2.0</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3096301</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3096302</th>\n",
       "      <td>4471818.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.429612e+10</td>\n",
       "      <td>LAND</td>\n",
       "      <td>2.0</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3096303</th>\n",
       "      <td>4471817.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.429629e+10</td>\n",
       "      <td>LAND</td>\n",
       "      <td>2.0</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3096304</th>\n",
       "      <td>4471819.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.429643e+10</td>\n",
       "      <td>LAND</td>\n",
       "      <td>2.0</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3096305</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3096306</th>\n",
       "      <td>4249464.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.426909e+10</td>\n",
       "      <td>LAND</td>\n",
       "      <td>1.0</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3096307</th>\n",
       "      <td>5416391.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.471480e+10</td>\n",
       "      <td>LAND</td>\n",
       "      <td>1.0</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3096308</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3096309</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3096310</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3096311</th>\n",
       "      <td>5658953.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.488710e+10</td>\n",
       "      <td>LAND</td>\n",
       "      <td>2.0</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3096312</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3096313 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            cic_id airline  admin_number flight_number  visa visa_type\n",
       "0              NaN     NaN           NaN           NaN   NaN       NaN\n",
       "1              NaN     NaN           NaN           NaN   NaN       NaN\n",
       "2              NaN     NaN           NaN           NaN   NaN       NaN\n",
       "3              NaN     NaN           NaN           NaN   NaN       NaN\n",
       "4              NaN     NaN           NaN           NaN   NaN       NaN\n",
       "5              NaN     NaN           NaN           NaN   NaN       NaN\n",
       "6              NaN     NaN           NaN           NaN   NaN       NaN\n",
       "7              NaN     NaN           NaN           NaN   NaN       NaN\n",
       "8              NaN     NaN           NaN           NaN   NaN       NaN\n",
       "9              NaN     NaN           NaN           NaN   NaN       NaN\n",
       "10             NaN     NaN           NaN           NaN   NaN       NaN\n",
       "11             NaN     NaN           NaN           NaN   NaN       NaN\n",
       "12             NaN     NaN           NaN           NaN   NaN       NaN\n",
       "13             NaN     NaN           NaN           NaN   NaN       NaN\n",
       "14             NaN     NaN           NaN           NaN   NaN       NaN\n",
       "15             NaN     NaN           NaN           NaN   NaN       NaN\n",
       "16             NaN     NaN           NaN           NaN   NaN       NaN\n",
       "17             NaN     NaN           NaN           NaN   NaN       NaN\n",
       "18             NaN     NaN           NaN           NaN   NaN       NaN\n",
       "19             NaN     NaN           NaN           NaN   NaN       NaN\n",
       "20             NaN     NaN           NaN           NaN   NaN       NaN\n",
       "21             NaN     NaN           NaN           NaN   NaN       NaN\n",
       "22             NaN     NaN           NaN           NaN   NaN       NaN\n",
       "23             NaN     NaN           NaN           NaN   NaN       NaN\n",
       "24             NaN     NaN           NaN           NaN   NaN       NaN\n",
       "25             NaN     NaN           NaN           NaN   NaN       NaN\n",
       "26             NaN     NaN           NaN           NaN   NaN       NaN\n",
       "27             NaN     NaN           NaN           NaN   NaN       NaN\n",
       "28             NaN     NaN           NaN           NaN   NaN       NaN\n",
       "29             NaN     NaN           NaN           NaN   NaN       NaN\n",
       "...            ...     ...           ...           ...   ...       ...\n",
       "3096283  5200122.0     NaN  9.466694e+10          LAND   2.0        B2\n",
       "3096284  5200121.0     NaN  9.466708e+10          LAND   2.0        B2\n",
       "3096285        NaN     NaN           NaN           NaN   NaN       NaN\n",
       "3096286        NaN     NaN           NaN           NaN   NaN       NaN\n",
       "3096287  2303672.0     NaN  7.870831e+08          LAND   1.0        B1\n",
       "3096288   625288.0     NaN  9.266689e+10          LAND   1.0        B1\n",
       "3096289  2873230.0     NaN  8.806588e+10          LAND   2.0        B2\n",
       "3096290  2873231.0     NaN  8.806625e+10          LAND   2.0        B2\n",
       "3096291  2873232.0     NaN  8.806640e+10          LAND   2.0        B2\n",
       "3096292        NaN     NaN           NaN           NaN   NaN       NaN\n",
       "3096293        NaN     NaN           NaN           NaN   NaN       NaN\n",
       "3096294   218224.0     NaN  9.251075e+10          LAND   2.0        B2\n",
       "3096295  2873233.0     NaN  9.356363e+10          LAND   2.0        B2\n",
       "3096296  2873234.0     NaN  9.356366e+10          LAND   2.0        B2\n",
       "3096297  3298796.0     NaN  9.379549e+10          LAND   1.0        B1\n",
       "3096298  4249463.0     NaN  9.428408e+10          LAND   1.0        B1\n",
       "3096299  1153287.0     NaN  6.878366e+08          LAND   2.0        B2\n",
       "3096300  1153288.0     NaN  6.880218e+08          LAND   2.0        B2\n",
       "3096301        NaN     NaN           NaN           NaN   NaN       NaN\n",
       "3096302  4471818.0     NaN  9.429612e+10          LAND   2.0        B2\n",
       "3096303  4471817.0     NaN  9.429629e+10          LAND   2.0        B2\n",
       "3096304  4471819.0     NaN  9.429643e+10          LAND   2.0        B2\n",
       "3096305        NaN     NaN           NaN           NaN   NaN       NaN\n",
       "3096306  4249464.0     NaN  9.426909e+10          LAND   1.0        B1\n",
       "3096307  5416391.0     NaN  9.471480e+10          LAND   1.0        B1\n",
       "3096308        NaN     NaN           NaN           NaN   NaN       NaN\n",
       "3096309        NaN     NaN           NaN           NaN   NaN       NaN\n",
       "3096310        NaN     NaN           NaN           NaN   NaN       NaN\n",
       "3096311  5658953.0     NaN  9.488710e+10          LAND   2.0        B2\n",
       "3096312        NaN     NaN           NaN           NaN   NaN       NaN\n",
       "\n",
       "[3096313 rows x 6 columns]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim_immigration_air.where(dim_immigration_air['flight_number'] == 'LAND')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cic_id                   610\n",
       "airline                  *GA\n",
       "admin_number     9.24611e+10\n",
       "flight_number          VPCSW\n",
       "visa                       2\n",
       "visa_type                 B2\n",
       "Name: 540, dtype: object"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim_immigration_air.iloc[540]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "dim_immigration_air['flight_number'] = dim_immigration_air[dim_immigration_air['flight_number'].apply(lambda x: str(x).isdigit())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "dim_immigration_air['flight_number'] = pd.to_numeric(dim_immigration_air['flight_number'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cic_id           float64\n",
       "airline           object\n",
       "admin_number     float64\n",
       "flight_number    float64\n",
       "visa             float64\n",
       "visa_type         object\n",
       "dtype: object"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim_immigration_air.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Extracting necessary information from i94 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "with open(\"I94_SAS_Labels_Descriptions.SAS\") as f:\n",
    "    contents = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "countries = contents[9:298]\n",
    "ports = contents[302:962]\n",
    "modes = contents[972:976]\n",
    "states = contents[981:1036]\n",
    "visa = contents[1046:1049]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country_code</th>\n",
       "      <th>country_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>582</td>\n",
       "      <td>MEXICO Air Sea, and Not Reported (I-94, no l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>236</td>\n",
       "      <td>AFGHANISTAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>101</td>\n",
       "      <td>ALBANIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>316</td>\n",
       "      <td>ALGERIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>102</td>\n",
       "      <td>ANDORRA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  country_code                                       country_name\n",
       "0         582     MEXICO Air Sea, and Not Reported (I-94, no l...\n",
       "1         236                                         AFGHANISTAN\n",
       "2         101                                             ALBANIA\n",
       "3         316                                             ALGERIA\n",
       "4         102                                             ANDORRA"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "country = [x.strip().split('=') for x in countries]\n",
    "country_code = [x[0].replace(\"'\",\"\") for x in country]\n",
    "country_name = [x[1].replace(\"'\",\"\") for x in country]\n",
    "df_country = pd.DataFrame({'country_code':country_code, 'country_name':country_name})\n",
    "df_country.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>port_code</th>\n",
       "      <th>port_loc_city</th>\n",
       "      <th>port_loc_state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ALC</td>\n",
       "      <td>ALCAN</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ANC</td>\n",
       "      <td>ANCHORAGE</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BAR</td>\n",
       "      <td>BAKER AAF - BAKER ISLAND</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DAC</td>\n",
       "      <td>DALTONS CACHE</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PIZ</td>\n",
       "      <td>DEW STATION PT LAY DEW</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  port_code             port_loc_city    port_loc_state\n",
       "0       ALC                     ALCAN   AK             \n",
       "1       ANC                 ANCHORAGE       AK         \n",
       "2       BAR  BAKER AAF - BAKER ISLAND                AK\n",
       "3       DAC             DALTONS CACHE           AK     \n",
       "4       PIZ    DEW STATION PT LAY DEW                AK"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "port = [x.strip().split('=') for x in ports]\n",
    "port_code = [x[0].replace(\"'\",\"\").strip('\\t') for x in port]\n",
    "port_loc = [x[1].replace(\"'\",\"\").strip('\\t') for x in port]\n",
    "port_loc_c = [x.split(',')[0] for x in port_loc]\n",
    "port_loc_s = [x.split(',')[-1] for x in port_loc]\n",
    "df_port = pd.DataFrame({'port_code':port_code, 'port_loc_city':port_loc_c, 'port_loc_state':port_loc_s})\n",
    "df_port.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>mode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Air</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Sea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Land</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>Not reported</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  code            mode\n",
       "0   1              Air\n",
       "1   2              Sea\n",
       "2   3             Land\n",
       "3   9    Not reported "
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mode = [x.strip().split('=') for x in modes]\n",
    "code = [x[0] for x in mode]\n",
    "mode_name = [x[1].replace(\"'\", \"\").strip(\";\") for x in mode]\n",
    "df_mode = pd.DataFrame({'code':code, 'mode':mode_name})\n",
    "df_mode.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state_code</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AL</td>\n",
       "      <td>ALABAMA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AK</td>\n",
       "      <td>ALASKA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AZ</td>\n",
       "      <td>ARIZONA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AR</td>\n",
       "      <td>ARKANSAS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CA</td>\n",
       "      <td>CALIFORNIA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  state_code       state\n",
       "0         AL     ALABAMA\n",
       "1         AK      ALASKA\n",
       "2         AZ     ARIZONA\n",
       "3         AR    ARKANSAS\n",
       "4         CA  CALIFORNIA"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state = [x.strip().split('=') for x in states]\n",
    "code = [x[0].replace(\"'\", \"\") for x in state]\n",
    "state_name = [x[1].replace(\"'\", \"\") for x in state]\n",
    "df_state = pd.DataFrame({'state_code':code, 'state':state_name})\n",
    "df_state.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>visa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Pleasure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Student</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  code       visa\n",
       "0   1    Business\n",
       "1   2    Pleasure\n",
       "2   3     Student"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visa_list = [x.strip().split('=') for x in visa]\n",
    "code = [x[0] for x in visa_list]\n",
    "visa_name = [x[1] for x in visa_list]\n",
    "df_visa = pd.DataFrame({'code':code, 'visa':visa_name})\n",
    "df_visa.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Dropping missing values and duplicate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>median_age</th>\n",
       "      <th>avg_household_size</th>\n",
       "      <th>state_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Silver Spring</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>33.8</td>\n",
       "      <td>2.60</td>\n",
       "      <td>MD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Quincy</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>41.0</td>\n",
       "      <td>2.39</td>\n",
       "      <td>MA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hoover</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>38.5</td>\n",
       "      <td>2.58</td>\n",
       "      <td>AL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rancho Cucamonga</td>\n",
       "      <td>California</td>\n",
       "      <td>34.5</td>\n",
       "      <td>3.18</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Newark</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>34.6</td>\n",
       "      <td>2.73</td>\n",
       "      <td>NJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Peoria</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>33.1</td>\n",
       "      <td>2.40</td>\n",
       "      <td>IL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Avondale</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>29.1</td>\n",
       "      <td>3.18</td>\n",
       "      <td>AZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>West Covina</td>\n",
       "      <td>California</td>\n",
       "      <td>39.8</td>\n",
       "      <td>3.56</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>O'Fallon</td>\n",
       "      <td>Missouri</td>\n",
       "      <td>36.0</td>\n",
       "      <td>2.77</td>\n",
       "      <td>MO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>High Point</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>35.5</td>\n",
       "      <td>2.65</td>\n",
       "      <td>NC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Folsom</td>\n",
       "      <td>California</td>\n",
       "      <td>40.9</td>\n",
       "      <td>2.62</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Philadelphia</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>34.1</td>\n",
       "      <td>2.61</td>\n",
       "      <td>PA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Wichita</td>\n",
       "      <td>Kansas</td>\n",
       "      <td>34.6</td>\n",
       "      <td>2.56</td>\n",
       "      <td>KS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Fort Myers</td>\n",
       "      <td>Florida</td>\n",
       "      <td>37.3</td>\n",
       "      <td>2.45</td>\n",
       "      <td>FL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Pittsburgh</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>32.9</td>\n",
       "      <td>2.13</td>\n",
       "      <td>PA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Laredo</td>\n",
       "      <td>Texas</td>\n",
       "      <td>28.8</td>\n",
       "      <td>3.66</td>\n",
       "      <td>TX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Berkeley</td>\n",
       "      <td>California</td>\n",
       "      <td>32.5</td>\n",
       "      <td>2.35</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Santa Clara</td>\n",
       "      <td>California</td>\n",
       "      <td>35.2</td>\n",
       "      <td>2.75</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Allen</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>33.5</td>\n",
       "      <td>2.67</td>\n",
       "      <td>PA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Hampton</td>\n",
       "      <td>Virginia</td>\n",
       "      <td>35.5</td>\n",
       "      <td>2.48</td>\n",
       "      <td>VA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Bolingbrook</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>33.7</td>\n",
       "      <td>3.42</td>\n",
       "      <td>IL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Frederick</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>36.1</td>\n",
       "      <td>2.48</td>\n",
       "      <td>MD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Sparks</td>\n",
       "      <td>Nevada</td>\n",
       "      <td>36.1</td>\n",
       "      <td>2.63</td>\n",
       "      <td>NV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Rancho Cordova</td>\n",
       "      <td>California</td>\n",
       "      <td>33.8</td>\n",
       "      <td>2.86</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Westminster</td>\n",
       "      <td>Colorado</td>\n",
       "      <td>37.8</td>\n",
       "      <td>2.63</td>\n",
       "      <td>CO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Lakewood</td>\n",
       "      <td>Colorado</td>\n",
       "      <td>37.7</td>\n",
       "      <td>2.29</td>\n",
       "      <td>CO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Flint</td>\n",
       "      <td>Michigan</td>\n",
       "      <td>35.3</td>\n",
       "      <td>2.38</td>\n",
       "      <td>MI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>New Haven</td>\n",
       "      <td>Connecticut</td>\n",
       "      <td>29.9</td>\n",
       "      <td>2.48</td>\n",
       "      <td>CT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Brooklyn Park</td>\n",
       "      <td>Minnesota</td>\n",
       "      <td>35.1</td>\n",
       "      <td>2.85</td>\n",
       "      <td>MN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Chula Vista</td>\n",
       "      <td>California</td>\n",
       "      <td>34.6</td>\n",
       "      <td>3.32</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1420</th>\n",
       "      <td>Miami</td>\n",
       "      <td>Florida</td>\n",
       "      <td>40.4</td>\n",
       "      <td>2.50</td>\n",
       "      <td>FL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1425</th>\n",
       "      <td>Apple Valley</td>\n",
       "      <td>California</td>\n",
       "      <td>34.3</td>\n",
       "      <td>3.03</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1435</th>\n",
       "      <td>Macon</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>36.0</td>\n",
       "      <td>2.46</td>\n",
       "      <td>GA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1443</th>\n",
       "      <td>Cleveland</td>\n",
       "      <td>Ohio</td>\n",
       "      <td>36.0</td>\n",
       "      <td>2.24</td>\n",
       "      <td>OH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1453</th>\n",
       "      <td>Tempe</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>28.8</td>\n",
       "      <td>2.44</td>\n",
       "      <td>AZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1470</th>\n",
       "      <td>Albany</td>\n",
       "      <td>New York</td>\n",
       "      <td>32.8</td>\n",
       "      <td>2.08</td>\n",
       "      <td>NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1479</th>\n",
       "      <td>Southfield</td>\n",
       "      <td>Michigan</td>\n",
       "      <td>41.6</td>\n",
       "      <td>2.27</td>\n",
       "      <td>MI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1495</th>\n",
       "      <td>Durham</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>33.2</td>\n",
       "      <td>2.40</td>\n",
       "      <td>NC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1501</th>\n",
       "      <td>Pharr</td>\n",
       "      <td>Texas</td>\n",
       "      <td>26.9</td>\n",
       "      <td>3.67</td>\n",
       "      <td>TX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1504</th>\n",
       "      <td>Spokane Valley</td>\n",
       "      <td>Washington</td>\n",
       "      <td>36.0</td>\n",
       "      <td>2.39</td>\n",
       "      <td>WA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1511</th>\n",
       "      <td>Grand Rapids</td>\n",
       "      <td>Michigan</td>\n",
       "      <td>32.1</td>\n",
       "      <td>2.56</td>\n",
       "      <td>MI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1530</th>\n",
       "      <td>Sunnyvale</td>\n",
       "      <td>California</td>\n",
       "      <td>35.7</td>\n",
       "      <td>2.74</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1543</th>\n",
       "      <td>Columbia</td>\n",
       "      <td>South Carolina</td>\n",
       "      <td>28.0</td>\n",
       "      <td>2.32</td>\n",
       "      <td>SC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1562</th>\n",
       "      <td>Fort Lauderdale</td>\n",
       "      <td>Florida</td>\n",
       "      <td>42.8</td>\n",
       "      <td>2.38</td>\n",
       "      <td>FL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1606</th>\n",
       "      <td>Warwick</td>\n",
       "      <td>Rhode Island</td>\n",
       "      <td>42.6</td>\n",
       "      <td>2.40</td>\n",
       "      <td>RI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1621</th>\n",
       "      <td>Aurora</td>\n",
       "      <td>Colorado</td>\n",
       "      <td>34.2</td>\n",
       "      <td>2.82</td>\n",
       "      <td>CO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1629</th>\n",
       "      <td>Bloomington</td>\n",
       "      <td>Minnesota</td>\n",
       "      <td>40.9</td>\n",
       "      <td>2.30</td>\n",
       "      <td>MN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1639</th>\n",
       "      <td>Canton</td>\n",
       "      <td>Ohio</td>\n",
       "      <td>33.4</td>\n",
       "      <td>2.32</td>\n",
       "      <td>OH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1735</th>\n",
       "      <td>Lansing</td>\n",
       "      <td>Michigan</td>\n",
       "      <td>31.4</td>\n",
       "      <td>2.39</td>\n",
       "      <td>MI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1748</th>\n",
       "      <td>Mayagüez</td>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>38.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1815</th>\n",
       "      <td>Laguna Niguel</td>\n",
       "      <td>California</td>\n",
       "      <td>45.8</td>\n",
       "      <td>2.58</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1816</th>\n",
       "      <td>Pine Hills</td>\n",
       "      <td>Florida</td>\n",
       "      <td>29.2</td>\n",
       "      <td>3.30</td>\n",
       "      <td>FL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1826</th>\n",
       "      <td>New York</td>\n",
       "      <td>New York</td>\n",
       "      <td>36.0</td>\n",
       "      <td>2.68</td>\n",
       "      <td>NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>Ponce</td>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>40.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004</th>\n",
       "      <td>Bayamón</td>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>39.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2063</th>\n",
       "      <td>Mobile</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>38.0</td>\n",
       "      <td>2.40</td>\n",
       "      <td>AL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2066</th>\n",
       "      <td>League City</td>\n",
       "      <td>Texas</td>\n",
       "      <td>35.9</td>\n",
       "      <td>2.72</td>\n",
       "      <td>TX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2573</th>\n",
       "      <td>Lafayette</td>\n",
       "      <td>Indiana</td>\n",
       "      <td>33.5</td>\n",
       "      <td>2.19</td>\n",
       "      <td>IN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2589</th>\n",
       "      <td>Guaynabo</td>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>42.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2726</th>\n",
       "      <td>Missoula</td>\n",
       "      <td>Montana</td>\n",
       "      <td>34.7</td>\n",
       "      <td>2.15</td>\n",
       "      <td>MT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>596 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  city           state  median_age  avg_household_size  \\\n",
       "0        Silver Spring        Maryland        33.8                2.60   \n",
       "1               Quincy   Massachusetts        41.0                2.39   \n",
       "2               Hoover         Alabama        38.5                2.58   \n",
       "3     Rancho Cucamonga      California        34.5                3.18   \n",
       "4               Newark      New Jersey        34.6                2.73   \n",
       "5               Peoria        Illinois        33.1                2.40   \n",
       "6             Avondale         Arizona        29.1                3.18   \n",
       "7          West Covina      California        39.8                3.56   \n",
       "8             O'Fallon        Missouri        36.0                2.77   \n",
       "9           High Point  North Carolina        35.5                2.65   \n",
       "10              Folsom      California        40.9                2.62   \n",
       "12        Philadelphia    Pennsylvania        34.1                2.61   \n",
       "13             Wichita          Kansas        34.6                2.56   \n",
       "15          Fort Myers         Florida        37.3                2.45   \n",
       "16          Pittsburgh    Pennsylvania        32.9                2.13   \n",
       "17              Laredo           Texas        28.8                3.66   \n",
       "18            Berkeley      California        32.5                2.35   \n",
       "19         Santa Clara      California        35.2                2.75   \n",
       "20               Allen    Pennsylvania        33.5                2.67   \n",
       "21             Hampton        Virginia        35.5                2.48   \n",
       "22         Bolingbrook        Illinois        33.7                3.42   \n",
       "23           Frederick        Maryland        36.1                2.48   \n",
       "24              Sparks          Nevada        36.1                2.63   \n",
       "25      Rancho Cordova      California        33.8                2.86   \n",
       "26         Westminster        Colorado        37.8                2.63   \n",
       "27            Lakewood        Colorado        37.7                2.29   \n",
       "28               Flint        Michigan        35.3                2.38   \n",
       "29           New Haven     Connecticut        29.9                2.48   \n",
       "30       Brooklyn Park       Minnesota        35.1                2.85   \n",
       "31         Chula Vista      California        34.6                3.32   \n",
       "...                ...             ...         ...                 ...   \n",
       "1420             Miami         Florida        40.4                2.50   \n",
       "1425      Apple Valley      California        34.3                3.03   \n",
       "1435             Macon         Georgia        36.0                2.46   \n",
       "1443         Cleveland            Ohio        36.0                2.24   \n",
       "1453             Tempe         Arizona        28.8                2.44   \n",
       "1470            Albany        New York        32.8                2.08   \n",
       "1479        Southfield        Michigan        41.6                2.27   \n",
       "1495            Durham  North Carolina        33.2                2.40   \n",
       "1501             Pharr           Texas        26.9                3.67   \n",
       "1504    Spokane Valley      Washington        36.0                2.39   \n",
       "1511      Grand Rapids        Michigan        32.1                2.56   \n",
       "1530         Sunnyvale      California        35.7                2.74   \n",
       "1543          Columbia  South Carolina        28.0                2.32   \n",
       "1562   Fort Lauderdale         Florida        42.8                2.38   \n",
       "1606           Warwick    Rhode Island        42.6                2.40   \n",
       "1621            Aurora        Colorado        34.2                2.82   \n",
       "1629       Bloomington       Minnesota        40.9                2.30   \n",
       "1639            Canton            Ohio        33.4                2.32   \n",
       "1735           Lansing        Michigan        31.4                2.39   \n",
       "1748          Mayagüez     Puerto Rico        38.1                 NaN   \n",
       "1815     Laguna Niguel      California        45.8                2.58   \n",
       "1816        Pine Hills         Florida        29.2                3.30   \n",
       "1826          New York        New York        36.0                2.68   \n",
       "1995             Ponce     Puerto Rico        40.5                 NaN   \n",
       "2004           Bayamón     Puerto Rico        39.4                 NaN   \n",
       "2063            Mobile         Alabama        38.0                2.40   \n",
       "2066       League City           Texas        35.9                2.72   \n",
       "2573         Lafayette         Indiana        33.5                2.19   \n",
       "2589          Guaynabo     Puerto Rico        42.2                 NaN   \n",
       "2726          Missoula         Montana        34.7                2.15   \n",
       "\n",
       "     state_code  \n",
       "0            MD  \n",
       "1            MA  \n",
       "2            AL  \n",
       "3            CA  \n",
       "4            NJ  \n",
       "5            IL  \n",
       "6            AZ  \n",
       "7            CA  \n",
       "8            MO  \n",
       "9            NC  \n",
       "10           CA  \n",
       "12           PA  \n",
       "13           KS  \n",
       "15           FL  \n",
       "16           PA  \n",
       "17           TX  \n",
       "18           CA  \n",
       "19           CA  \n",
       "20           PA  \n",
       "21           VA  \n",
       "22           IL  \n",
       "23           MD  \n",
       "24           NV  \n",
       "25           CA  \n",
       "26           CO  \n",
       "27           CO  \n",
       "28           MI  \n",
       "29           CT  \n",
       "30           MN  \n",
       "31           CA  \n",
       "...         ...  \n",
       "1420         FL  \n",
       "1425         CA  \n",
       "1435         GA  \n",
       "1443         OH  \n",
       "1453         AZ  \n",
       "1470         NY  \n",
       "1479         MI  \n",
       "1495         NC  \n",
       "1501         TX  \n",
       "1504         WA  \n",
       "1511         MI  \n",
       "1530         CA  \n",
       "1543         SC  \n",
       "1562         FL  \n",
       "1606         RI  \n",
       "1621         CO  \n",
       "1629         MN  \n",
       "1639         OH  \n",
       "1735         MI  \n",
       "1748         PR  \n",
       "1815         CA  \n",
       "1816         FL  \n",
       "1826         NY  \n",
       "1995         PR  \n",
       "2004         PR  \n",
       "2063         AL  \n",
       "2066         TX  \n",
       "2573         IN  \n",
       "2589         PR  \n",
       "2726         MT  \n",
       "\n",
       "[596 rows x 5 columns]"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# immigration data\n",
    "fact_immigration.dropna(subset=['cic_id'])\n",
    "dim_immigration_personal.dropna(subset=['cic_id'])\n",
    "dim_immigration_air.dropna(subset=['cic_id'])\n",
    "\n",
    "fact_immigration.drop_duplicates(subset = 'cic_id', keep = 'first')\n",
    "dim_immigration_personal.drop_duplicates(subset = 'cic_id', keep = 'first')\n",
    "dim_immigration_air.drop_duplicates(subset = 'cic_id', keep = 'first')\n",
    "\n",
    "# temperature data\n",
    "df_temp_us.dropna()\n",
    "df_temp_us.drop_duplicates(subset = 'dt', keep = 'first')\n",
    "\n",
    "# demography data\n",
    "df_demo_info.dropna()\n",
    "df_demo_stat.dropna()\n",
    "df_demo_info.drop_duplicates(subset = 'city', keep = 'first')\n",
    "df_demo_stat.drop_duplicates(subset = 'city', keep = 'first')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 3: Define the Data Model\n",
    "#### 3.1 Conceptual Data Model\n",
    "<img width=\"802\" alt=\"Screen Shot 2021-09-09 at 10 46 07 PM\" src=\"https://user-images.githubusercontent.com/79597984/132707777-a124e5d3-03d0-45c6-9bd5-61a8fc6f5618.png\">\n",
    "\n",
    "#### 3.2 Mapping Out Data Pipelines\n",
    "List the steps necessary to pipeline the data into the chosen data model\n",
    "1. Create the data model by coping the drop and create statements from `create_tables.sql` file into the query editor in redshift.\n",
    "2. Run step 1 & 2 above to clean the data.\n",
    "3. Insert the data into the tables created by running the below code in step `4.1`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 4: Run Pipelines to Model the Data \n",
    "#### 4.1 Create the data model\n",
    "Build the data pipelines to create the data model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Write code here\n",
    "conn = psycopg2.connect(\"host=redshift-cluster-1.*****.us-west-2.redshift.amazonaws.com dbname=dev user=awsuser password=***** port=5439\")\n",
    "cur = conn.cursor()\n",
    "conn.autocommit = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "for index, row in fact_immigration.head(2000).iterrows():\n",
    "    cur.execute(insert_fact, list(row.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "for index, row in dim_immigration_personal.head(2000).iterrows():\n",
    "    cur.execute(insert_dim_imm_per, list(row.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "for index, row in dim_immigration_air.head(2000).iterrows():\n",
    "    cur.execute(insert_dim_imm_air, list(row.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "for index, row in df_demo_info.iterrows():\n",
    "    cur.execute(insert_dim_demo_info, list(row.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "for index, row in df_demo_stat.iterrows():\n",
    "    cur.execute(insert_dim_demo_stat, list(row.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "for index, row in df_temp_us.head(2000).iterrows():\n",
    "    cur.execute(insert_dim_temp, list(row.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.2 Data Quality Checks\n",
    "Explain the data quality checks you'll perform to ensure the pipeline ran as expected. These could include:\n",
    " * Integrity constraints on the relational database (e.g., unique key, data type, etc.)\n",
    " * Unit tests for the scripts to ensure they are doing the right thing\n",
    " * Source/Count checks to ensure completeness\n",
    " \n",
    "Run Quality Checks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Checking if the duplicated rows are all removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "There's no duplicated rows\n"
     ]
    }
   ],
   "source": [
    "duplicate_query = \"\"\"\n",
    "    SELECT cic_id, COUNT(cic_id)\n",
    "    FROM fact_immigration\n",
    "    GROUP BY cic_id\n",
    "    HAVING COUNT(cic_id)>1;\n",
    "\"\"\"\n",
    "cur.execute(duplicate_query)\n",
    "data = cur.fetchall()\n",
    "print(data)\n",
    "\n",
    "if not data:\n",
    "    print(\"There's no duplicated rows\")\n",
    "else:\n",
    "    print(f\"There's {len(data)} duplicated rows in cic_id in the table fact_immigration\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "There's no duplicated rows\n"
     ]
    }
   ],
   "source": [
    "duplicate_query = \"\"\"\n",
    "    SELECT cic_id, COUNT(cic_id)\n",
    "    FROM dim_immigration_personal\n",
    "    GROUP BY cic_id\n",
    "    HAVING COUNT(cic_id)>1;\n",
    "\"\"\"\n",
    "cur.execute(duplicate_query)\n",
    "data = cur.fetchall()\n",
    "print(data)\n",
    "\n",
    "if not data:\n",
    "    print(\"There's no duplicated rows\")\n",
    "else:\n",
    "    print(f\"There's {len(data)} duplicated rows in cic_id in the table dim_immigration_personal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "There's no duplicated rows\n"
     ]
    }
   ],
   "source": [
    "duplicate_query = \"\"\"\n",
    "    SELECT cic_id, COUNT(cic_id)\n",
    "    FROM dim_immigration_air\n",
    "    GROUP BY cic_id\n",
    "    HAVING COUNT(cic_id)>1;\n",
    "\"\"\"\n",
    "cur.execute(duplicate_query)\n",
    "data = cur.fetchall()\n",
    "print(data)\n",
    "\n",
    "if not data:\n",
    "    print(\"There's no duplicated rows\")\n",
    "else:\n",
    "    print(f\"There's {len(data)} duplicated rows in cic_id in the table dim_immigration_air\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Silver Spring', 5), ('Quincy', 5), ('Hoover', 4), ('Rancho Cucamonga', 5), ('Newark', 5), ('Peoria', 10), ('Avondale', 5), ('West Covina', 5), (\"O'Fallon\", 5), ('High Point', 5), ('Folsom', 5), ('Philadelphia', 5), ('Wichita', 5), ('Fort Myers', 4), ('Pittsburgh', 5), ('Laredo', 5), ('Berkeley', 5), ('Santa Clara', 5), ('Allen', 10), ('Hampton', 5), ('Bolingbrook', 5), ('Frederick', 5), ('Sparks', 5), ('Rancho Cordova', 5), ('Westminster', 10), ('Lakewood', 10), ('Flint', 5), ('New Haven', 5), ('Brooklyn Park', 5), ('Chula Vista', 5), ('Danbury', 5), ('Framingham', 5), ('Saint Petersburg', 5), ('Miami Gardens', 3), ('Salt Lake City', 5), ('Suffolk', 5), ('North Little Rock', 4), ('Jurupa Valley', 5), ('Los Angeles', 5), ('Flower Mound', 5), ('Vacaville', 5), ('Clarksville', 5), ('New Britain', 4), ('Tulsa', 5), ('Seattle', 5), ('Mesa', 5), ('Yonkers', 5), ('Camden', 4), ('Alexandria', 5), ('Jonesboro', 5), ('El Monte', 5), ('Roswell', 5), ('Omaha', 5), ('Troy', 5), ('Winston-Salem', 5), ('Corpus Christi', 5), ('Atlanta', 5), ('Bryan', 5), ('Lynchburg', 5), ('Columbia', 15), ('Killeen', 5), ('Nashville', 5), ('Somerville', 5), ('Bakersfield', 5), ('Montgomery', 5), ('Huntsville', 5), ('Greensboro', 5), ('Turlock', 5), ('Lynwood', 4), ('El Paso', 5), ('Lexington-Fayette  county', 5), ('Rock Hill', 5), ('Richardson', 5), ('Waco', 5), ('San Buenaventura', 5), ('Stamford', 5), ('Vallejo', 5), ('Denver', 5), ('Springdale', 5), ('Chino', 5), ('Toms River', 5), ('Lynn', 5), ('Lawton', 5), ('Garland', 5), ('Layton', 5), ('Bloomington', 15), ('Newton', 5), ('Clearwater', 5), ('Kenner', 5), ('Las Cruces', 5), ('Yakima', 5), ('Des Moines', 5), ('Wichita Falls', 5), ('Wilmington', 10), ('Cranston', 5), ('Amarillo', 5), ('Buffalo', 5), ('Livonia', 5), ('San Leandro', 5), ('Fresno', 5), ('Saint George', 5), ('San Juan', 3), ('Redlands', 5), ('Thousand Oaks', 5), ('Rio Rancho', 5), ('Provo', 5), ('Tallahassee', 5), ('Aurora', 10), ('Minneapolis', 5), ('Anaheim', 5), ('San Marcos', 5), ('Norwalk', 10), ('Fort Worth', 5), ('Cambridge', 5), ('Deerfield Beach', 5), ('Beaumont', 5), ('Spring Valley', 5), ('Sioux City', 5), ('Alafaya', 4), ('Washington', 5), ('Grand Prairie', 5), ('Waukesha', 5), ('Miami Beach', 4), ('North Las Vegas', 5), ('Fort Smith', 5), ('Salinas', 5), ('Springfield', 15), ('Bellingham', 5), ('Green Bay', 5), ('Maple Grove', 5), ('Escondido', 5), ('Rockford', 5), ('Memphis', 5), ('Caguas', 2), ('Metairie', 5), ('Tracy', 5), ('Champaign', 4), ('West Palm Beach', 5), ('Beaverton', 5), ('Ogden', 5), ('Decatur', 5), ('Pompano Beach', 5), ('Nashua', 5), ('Vancouver', 5), ('Fargo', 5), ('El Cajon', 5), ('Lancaster', 5), ('Miramar', 4), ('Riverview', 5), ('Arlington Heights', 4), ('Lorain', 5), ('Mesquite', 5), ('Appleton', 5), ('Johns Creek', 5), ('Nampa', 5), ('Sterling Heights', 4), ('Tacoma', 5), ('Manchester', 5), ('Overland Park', 5), ('Cicero', 5), ('Weston', 5), ('Meridian', 5), ('Trenton', 5), ('Temecula', 5), ('Saint Charles', 5), ('Antioch', 5), ('Eugene', 5), ('Edinburg', 3), ('Huntington Beach', 5), ('Torrance', 5), ('South Bend', 5), ('Bethlehem', 4), ('Birmingham', 5), ('Hawthorne', 5), ('Boca Raton', 5), ('Vista', 4), ('Brockton', 5), ('New Rochelle', 5), ('Dearborn', 5), ('Charleston', 5), ('Elizabeth', 5), ('Syracuse', 5), ('Redding', 5), ('Scottsdale', 5), ('Glendale', 10), ('Fishers', 4), ('Waldorf', 5), ('Las Vegas', 5), ('Victoria', 4), ('Anchorage', 5), ('San Diego', 5), ('Dayton', 5), ('Auburn', 5), ('Charlotte', 5), ('Gulfport', 4), ('Abilene', 5), ('Centreville', 5), ('Pleasanton', 5), ('Waterbury', 5), ('Davie', 5), ('Houston', 5), ('Concord', 10), ('Eagan', 5), ('Duluth', 5), ('Carolina', 2), ('Ellicott City', 5), ('Port Saint Lucie', 5), ('Greeley', 5), ('Ames', 4), ('West Jordan', 5), ('Chico', 5), ('Chino Hills', 5), ('New Bedford', 5), ('San Bernardino', 5), ('Longmont', 5), ('Lincoln', 5), ('Pasco', 5), ('Cincinnati', 5), ('New Braunfels', 5), ('Union City', 10), ('Fontana', 5), ('Milwaukee', 5), ('Racine', 5), ('Santa Maria', 5), ('Marysville', 5), ('Inglewood', 5), ('Cedar Rapids', 5), ('German', 5), ('Highlands Ranch', 5), ('Tustin', 5), ('Kent', 5), ('Urban Honolulu', 5), ('Richmond', 10), ('Deltona', 5), ('Kissimmee', 4), ('San Mateo', 5), ('Fall River', 5), ('Carmichael', 5), ('Lauderhill', 5), ('Worcester', 5), ('Providence', 5), ('Fayetteville', 10), ('Santa Rosa', 5), ('Lakeland', 5), ('Boulder', 5), ('Bayonne', 4), ('Santa Barbara', 5), ('Yuba City', 5), ('Palo Alto', 5), ('Pueblo', 5), ('The Villages', 3), ('Fort Wayne', 5), ('Santa Ana', 5), ('Bismarck', 5), ('Phoenix', 5), ('Daly City', 5), ('South San Francisco', 5), ('Independence', 5), ('Kennewick', 5), ('Flagstaff', 5), ('Brandon', 5), ('Kansas City', 10), ('Waukegan', 5), ('Fort Collins', 5), ('Jacksonville', 10), ('Cary', 5), ('Saint Joseph', 5), ('Melbourne', 5), ('Palm Bay', 5), ('Plantation', 4), ('Olathe', 5), ('Sioux Falls', 5), ('Portsmouth', 5), ('Jackson', 10), ('Spokane', 5), ('Colorado Springs', 5), ('McKinney', 5), ('Henderson', 5), ('Norfolk', 5), ('Arvada', 5), ('Hollywood', 5), ('Chesapeake', 5), ('Columbus', 10), ('Spring Hill', 5), ('Kenosha', 5), ('Kendall', 4), ('Redondo Beach', 5), ('Walnut Creek', 4), ('Mission', 3), ('McAllen', 5), ('Cheektowaga', 4), ('Oceanside', 5), ('Orlando', 5), ('Parma', 5), ('Harlingen', 3), ('Pembroke Pines', 5), ('Alhambra', 5), ('Brentwood', 5), ('Riverside', 5), ('Menifee', 5), ('Kalamazoo', 5), ('Carson', 5), ('Ann Arbor', 5), ('Farmington Hills', 5), ('Missouri City', 4), ('Orange', 5), ('Everett', 5), ('Citrus Heights', 5), ('Gainesville', 5), ('Milpitas', 5), ('Tampa', 5), ('Santa Monica', 5), ('Eau Claire', 5), ('Enterprise', 5), ('Shawnee', 5), ('North Charleston', 5), ('Boynton Beach', 4), ('Temple', 5), ('Rockville', 5), ('Cape Coral', 5), ('Manteca', 5), ('Little Rock', 5), ('Oxnard', 5), ('Bk', 5), ('Evanston', 5), ('Atascocita', 5), ('Surprise', 5), ('Dothan', 5), ('Rapid City', 5), (\"Lee's Summit\", 5), ('Warren', 5), ('Erie', 5), ('Mountain View', 5), ('West Valley City', 5), ('Hartford', 5), ('Fremont', 5), ('Elgin', 5), ('Greenville', 5), ('Gastonia', 5), ('Frisco', 5), ('Oklahoma City', 5), ('Carlsbad', 5), ('Pasadena', 10), ('Naperville', 5), ('Johnson City', 5), ('Goodyear', 5), ('Wyoming', 5), ('Reading', 5), ('Rochester Hills', 5), ('Madison', 5), ('Portland', 10), ('College Station', 5), ('Lewisville', 5), ('Raleigh', 5), ('Mount Vernon', 5), ('Dallas', 5), ('San Tan Valley', 5), ('East Orange', 5), ('Austin', 5), ('Casas Adobes', 5), ('Indianapolis', 5), ('Renton', 5), ('Odessa', 5), ('Round Rock', 5), ('Santa Fe', 5), ('Akron', 5), ('San Jose', 5), ('Saint Paul', 5), ('Muncie', 4), ('Victorville', 5), ('Murfreesboro', 5), ('Chattanooga', 5), ('Fairfield', 5), ('Toledo', 5), ('Asheville', 5), ('Savannah', 5), ('Louisville/Jefferson County metro government', 5), ('Yorba Linda', 5), ('Billings', 5), ('Denton', 5), ('Long Beach', 5), ('Tuscaloosa', 5), ('Elk Grove', 5), ('Paradise', 5), ('Sandy Springs', 5), ('Pearland', 5), ('Virginia Beach', 5), ('Roseville', 5), ('Homestead', 3), ('Iowa City', 5), ('Arden-Arcade', 5), ('Largo', 5), ('Carrollton', 5), ('Chandler', 5), ('Irvine', 5), ('Medford', 5), ('Coral Springs', 5), ('Bossier City', 5), ('Woodbury', 4), ('Boston', 5), ('Pittsburg', 5), ('San Ramon', 5), ('Reno', 5), ('Topeka', 5), ('Newport News', 5), ('Poinciana', 5), ('Compton', 5), ('Cedar Park', 5), ('Merced', 5), ('Shreveport', 5), ('Palatine', 4), ('San Angelo', 5), ('Passaic', 4), ('Lake Charles', 5), ('North Richland Hills', 5), ('Boise', 5), ('Carmel', 4), ('Palmdale', 5), ('Baltimore', 5), ('Indio', 5), ('Florence-Graham', 3), ('Santa Clarita', 5), ('Buena Park', 5), ('San Clemente', 4), ('Lawrence', 9), ('Downey', 5), ('Lafayette', 9), ('Newport Beach', 4), ('Schenectady', 5), ('South Gate', 5), ('Brownsville', 5), ('Costa Mesa', 5), ('Tyler', 5), ('Napa', 5), ('Centennial', 5), ('Sunrise', 4), ('Tucson', 5), ('Fullerton', 5), ('Lake Forest', 5), ('Stockton', 5), ('San Antonio', 5), ('Orem', 5), ('Norman', 5), ('Youngs', 5), ('Hayward', 5), ('Sandy', 5), ('Moreno Valley', 5), ('Delray Beach', 4), ('Gresham', 5), ('Federal Way', 5), ('Waterloo', 5), ('Jersey City', 5), ('Mission Viejo', 5), ('Dale City', 5), ('Albuquerque', 5), ('Plano', 5), ('Hesperia', 5), ('Lehigh Acres', 5), ('Pawtucket', 5), (\"Town 'n' Country\", 5), ('Saint Cloud', 5), ('Midland', 5), ('Chicago', 5), ('Knoxville', 5), ('Westland', 5), ('Yuma', 5), ('Roanoke', 5), ('Rialto', 5), ('Pomona', 5), ('Warner Robins', 5), ('East Los Angeles', 5), ('Simi Valley', 5), ('Davenport', 5), ('Thornton', 5), ('Gary', 5), ('Palm Coast', 5), ('Hialeah', 4), ('Clifton', 5), ('Bellflower', 5), ('Broomfield', 5), ('Joliet', 5), ('San Francisco', 5), ('Camarillo', 5), ('Skokie', 4), ('Redwood City', 5), ('Evansville', 5), ('Hillsboro', 5), ('The Woodlands', 5), ('Longview', 5), ('Upland', 5), ('Sunrise Manor', 5), ('Lubbock', 5), ('Kirkland', 5), ('Garden Grove', 5), ('Baton Rouge', 5), ('Livermore', 5), ('Paterson', 5), ('Conroe', 5), ('Edmond', 5), ('Sacramento', 5), ('Detroit', 5), ('Ontario', 5), ('Alameda', 5), ('Clovis', 5), ('Gilbert', 5), ('Hammond', 5), ('Saint Louis', 5), ('Athens-Clarke County unified government', 5), ('Scranton', 4), ('Modesto', 5), ('Perris', 4), ('South Jordan', 3), ('Visalia', 5), ('Davis', 5), ('Gaithersburg', 5), ('Albany', 10), ('Plymouth', 5), ('Corona', 5), ('Rochester', 10), ('Oshkosh', 5), ('Baldwin Park', 5), ('Oakland', 5), ('Augusta-Richmond County consolidated government', 5), ('Salem', 5), ('Schaumburg', 5), ('Lowell', 5), ('Glen Burnie', 5), ('Bend', 5), ('Bridgeport', 5), ('Broken Arrow', 5), ('New Orleans', 5), ('Arlington', 10), ('Bellevue', 5), ('Irving', 5), ('Whittier', 5), ('Bay', 5), ('Loveland', 5), ('Mount Pleasant', 4), ('Hemet', 5), ('Franklin', 4), ('Sugar Land', 4), ('Murrieta', 5), ('Miami', 5), ('Apple Valley', 5), ('Macon', 5), ('Cleveland', 5), ('Tempe', 5), ('Southfield', 5), ('Durham', 5), ('Pharr', 3), ('Spokane Valley', 5), ('Grand Rapids', 5), ('Sunnyvale', 5), ('Fort Lauderdale', 5), ('Warwick', 4), ('Canton', 4), ('Lansing', 5), ('Mayagüez', 2), ('Laguna Niguel', 4), ('Pine Hills', 4), ('New York', 5), ('Mobile', 5), ('League City', 4), ('Guaynabo', 2), ('Missoula', 5)]\n",
      "There's 565 duplicated rows in city in the table dim_demo_info\n"
     ]
    }
   ],
   "source": [
    "duplicate_query = \"\"\"\n",
    "    SELECT city, COUNT(city)\n",
    "    FROM dim_demo_info\n",
    "    GROUP BY city\n",
    "    HAVING COUNT(city)>1;\n",
    "\"\"\"\n",
    "cur.execute(duplicate_query)\n",
    "data = cur.fetchall()\n",
    "print(data)\n",
    "\n",
    "if not data:\n",
    "    print(\"There's no duplicated rows\")\n",
    "else:\n",
    "    print(f\"There's {len(data)} duplicated rows in city in the table dim_demo_info\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Silver Spring', 5), ('Quincy', 5), ('Hoover', 4), ('Rancho Cucamonga', 5), ('Newark', 5), ('Peoria', 10), ('Avondale', 5), ('West Covina', 5), (\"O'Fallon\", 5), ('High Point', 5), ('Folsom', 5), ('Philadelphia', 5), ('Wichita', 5), ('Fort Myers', 4), ('Pittsburgh', 5), ('Laredo', 5), ('Berkeley', 5), ('Santa Clara', 5), ('Allen', 10), ('Hampton', 5), ('Bolingbrook', 5), ('Frederick', 5), ('Sparks', 5), ('Rancho Cordova', 5), ('Westminster', 10), ('Lakewood', 10), ('Flint', 5), ('New Haven', 5), ('Brooklyn Park', 5), ('Chula Vista', 5), ('Danbury', 5), ('Framingham', 5), ('Saint Petersburg', 5), ('Miami Gardens', 3), ('Salt Lake City', 5), ('Suffolk', 5), ('North Little Rock', 4), ('Jurupa Valley', 5), ('Los Angeles', 5), ('Flower Mound', 5), ('Vacaville', 5), ('Clarksville', 5), ('New Britain', 4), ('Tulsa', 5), ('Seattle', 5), ('Mesa', 5), ('Yonkers', 5), ('Camden', 4), ('Alexandria', 5), ('Jonesboro', 5), ('El Monte', 5), ('Roswell', 5), ('Omaha', 5), ('Troy', 5), ('Winston-Salem', 5), ('Corpus Christi', 5), ('Atlanta', 5), ('Bryan', 5), ('Lynchburg', 5), ('Columbia', 15), ('Killeen', 5), ('Nashville', 5), ('Somerville', 5), ('Bakersfield', 5), ('Montgomery', 5), ('Huntsville', 5), ('Greensboro', 5), ('Turlock', 5), ('Lynwood', 4), ('El Paso', 5), ('Lexington-Fayette  county', 5), ('Rock Hill', 5), ('Richardson', 5), ('Waco', 5), ('San Buenaventura', 5), ('Stamford', 5), ('Vallejo', 5), ('Denver', 5), ('Springdale', 5), ('Chino', 5), ('Toms River', 5), ('Lynn', 5), ('Lawton', 5), ('Garland', 5), ('Layton', 5), ('Bloomington', 15), ('Newton', 5), ('Clearwater', 5), ('Kenner', 5), ('Las Cruces', 5), ('Yakima', 5), ('Des Moines', 5), ('Wichita Falls', 5), ('Wilmington', 10), ('Cranston', 5), ('Amarillo', 5), ('Buffalo', 5), ('Livonia', 5), ('San Leandro', 5), ('Fresno', 5), ('Saint George', 5), ('San Juan', 3), ('Redlands', 5), ('Thousand Oaks', 5), ('Rio Rancho', 5), ('Provo', 5), ('Tallahassee', 5), ('Aurora', 10), ('Minneapolis', 5), ('Anaheim', 5), ('San Marcos', 5), ('Norwalk', 10), ('Fort Worth', 5), ('Cambridge', 5), ('Deerfield Beach', 5), ('Beaumont', 5), ('Spring Valley', 5), ('Sioux City', 5), ('Alafaya', 4), ('Washington', 5), ('Grand Prairie', 5), ('Waukesha', 5), ('Miami Beach', 4), ('North Las Vegas', 5), ('Fort Smith', 5), ('Salinas', 5), ('Springfield', 15), ('Bellingham', 5), ('Green Bay', 5), ('Maple Grove', 5), ('Escondido', 5), ('Rockford', 5), ('Memphis', 5), ('Caguas', 2), ('Metairie', 5), ('Tracy', 5), ('Champaign', 4), ('West Palm Beach', 5), ('Beaverton', 5), ('Ogden', 5), ('Decatur', 5), ('Pompano Beach', 5), ('Nashua', 5), ('Vancouver', 5), ('Fargo', 5), ('El Cajon', 5), ('Lancaster', 5), ('Miramar', 4), ('Riverview', 5), ('Arlington Heights', 4), ('Lorain', 5), ('Mesquite', 5), ('Appleton', 5), ('Johns Creek', 5), ('Nampa', 5), ('Sterling Heights', 4), ('Tacoma', 5), ('Manchester', 5), ('Overland Park', 5), ('Cicero', 5), ('Weston', 5), ('Meridian', 5), ('Trenton', 5), ('Temecula', 5), ('Saint Charles', 5), ('Antioch', 5), ('Eugene', 5), ('Edinburg', 3), ('Huntington Beach', 5), ('Torrance', 5), ('South Bend', 5), ('Bethlehem', 4), ('Birmingham', 5), ('Hawthorne', 5), ('Boca Raton', 5), ('Vista', 4), ('Brockton', 5), ('New Rochelle', 5), ('Dearborn', 5), ('Charleston', 5), ('Elizabeth', 5), ('Syracuse', 5), ('Redding', 5), ('Scottsdale', 5), ('Glendale', 10), ('Fishers', 4), ('Waldorf', 5), ('Las Vegas', 5), ('Victoria', 4), ('Anchorage', 5), ('San Diego', 5), ('Dayton', 5), ('Auburn', 5), ('Charlotte', 5), ('Gulfport', 4), ('Abilene', 5), ('Centreville', 5), ('Pleasanton', 5), ('Waterbury', 5), ('Davie', 5), ('Houston', 5), ('Concord', 10), ('Eagan', 5), ('Duluth', 5), ('Carolina', 2), ('Ellicott City', 5), ('Port Saint Lucie', 5), ('Greeley', 5), ('Ames', 4), ('West Jordan', 5), ('Chico', 5), ('Chino Hills', 5), ('New Bedford', 5), ('San Bernardino', 5), ('Longmont', 5), ('Lincoln', 5), ('Pasco', 5), ('Cincinnati', 5), ('New Braunfels', 5), ('Union City', 10), ('Fontana', 5), ('Milwaukee', 5), ('Racine', 5), ('Santa Maria', 5), ('Marysville', 5), ('Inglewood', 5), ('Cedar Rapids', 5), ('German', 5), ('Highlands Ranch', 5), ('Tustin', 5), ('Kent', 5), ('Urban Honolulu', 5), ('Richmond', 10), ('Deltona', 5), ('Kissimmee', 4), ('San Mateo', 5), ('Fall River', 5), ('Carmichael', 5), ('Lauderhill', 5), ('Worcester', 5), ('Providence', 5), ('Fayetteville', 10), ('Santa Rosa', 5), ('Lakeland', 5), ('Boulder', 5), ('Bayonne', 4), ('Santa Barbara', 5), ('Yuba City', 5), ('Palo Alto', 5), ('Pueblo', 5), ('The Villages', 3), ('Fort Wayne', 5), ('Santa Ana', 5), ('Bismarck', 5), ('Phoenix', 5), ('Daly City', 5), ('South San Francisco', 5), ('Independence', 5), ('Kennewick', 5), ('Flagstaff', 5), ('Brandon', 5), ('Kansas City', 10), ('Waukegan', 5), ('Fort Collins', 5), ('Jacksonville', 10), ('Cary', 5), ('Saint Joseph', 5), ('Melbourne', 5), ('Palm Bay', 5), ('Plantation', 4), ('Olathe', 5), ('Sioux Falls', 5), ('Portsmouth', 5), ('Jackson', 10), ('Spokane', 5), ('Colorado Springs', 5), ('McKinney', 5), ('Henderson', 5), ('Norfolk', 5), ('Arvada', 5), ('Hollywood', 5), ('Chesapeake', 5), ('Columbus', 10), ('Spring Hill', 5), ('Kenosha', 5), ('Kendall', 4), ('Redondo Beach', 5), ('Walnut Creek', 4), ('Mission', 3), ('McAllen', 5), ('Cheektowaga', 4), ('Oceanside', 5), ('Orlando', 5), ('Parma', 5), ('Harlingen', 3), ('Pembroke Pines', 5), ('Alhambra', 5), ('Brentwood', 5), ('Riverside', 5), ('Menifee', 5), ('Kalamazoo', 5), ('Carson', 5), ('Ann Arbor', 5), ('Farmington Hills', 5), ('Missouri City', 4), ('Orange', 5), ('Everett', 5), ('Citrus Heights', 5), ('Gainesville', 5), ('Milpitas', 5), ('Tampa', 5), ('Santa Monica', 5), ('Eau Claire', 5), ('Enterprise', 5), ('Shawnee', 5), ('North Charleston', 5), ('Boynton Beach', 4), ('Temple', 5), ('Rockville', 5), ('Cape Coral', 5), ('Manteca', 5), ('Little Rock', 5), ('Oxnard', 5), ('Bk', 5), ('Evanston', 5), ('Atascocita', 5), ('Surprise', 5), ('Dothan', 5), ('Rapid City', 5), (\"Lee's Summit\", 5), ('Warren', 5), ('Erie', 5), ('Mountain View', 5), ('West Valley City', 5), ('Hartford', 5), ('Fremont', 5), ('Elgin', 5), ('Greenville', 5), ('Gastonia', 5), ('Frisco', 5), ('Oklahoma City', 5), ('Carlsbad', 5), ('Pasadena', 10), ('Naperville', 5), ('Johnson City', 5), ('Goodyear', 5), ('Wyoming', 5), ('Reading', 5), ('Rochester Hills', 5), ('Madison', 5), ('Portland', 10), ('College Station', 5), ('Lewisville', 5), ('Raleigh', 5), ('Mount Vernon', 5), ('Dallas', 5), ('San Tan Valley', 5), ('East Orange', 5), ('Austin', 5), ('Casas Adobes', 5), ('Indianapolis', 5), ('Renton', 5), ('Odessa', 5), ('Round Rock', 5), ('Santa Fe', 5), ('Akron', 5), ('San Jose', 5), ('Saint Paul', 5), ('Muncie', 4), ('Victorville', 5), ('Murfreesboro', 5), ('Chattanooga', 5), ('Fairfield', 5), ('Toledo', 5), ('Asheville', 5), ('Savannah', 5), ('Louisville/Jefferson County metro government', 5), ('Yorba Linda', 5), ('Billings', 5), ('Denton', 5), ('Long Beach', 5), ('Tuscaloosa', 5), ('Elk Grove', 5), ('Paradise', 5), ('Sandy Springs', 5), ('Pearland', 5), ('Virginia Beach', 5), ('Roseville', 5), ('Homestead', 3), ('Iowa City', 5), ('Arden-Arcade', 5), ('Largo', 5), ('Carrollton', 5), ('Chandler', 5), ('Irvine', 5), ('Medford', 5), ('Coral Springs', 5), ('Bossier City', 5), ('Woodbury', 4), ('Boston', 5), ('Pittsburg', 5), ('San Ramon', 5), ('Reno', 5), ('Topeka', 5), ('Newport News', 5), ('Poinciana', 5), ('Compton', 5), ('Cedar Park', 5), ('Merced', 5), ('Shreveport', 5), ('Palatine', 4), ('San Angelo', 5), ('Passaic', 4), ('Lake Charles', 5), ('North Richland Hills', 5), ('Boise', 5), ('Carmel', 4), ('Palmdale', 5), ('Baltimore', 5), ('Indio', 5), ('Florence-Graham', 3), ('Santa Clarita', 5), ('Buena Park', 5), ('San Clemente', 4), ('Lawrence', 9), ('Downey', 5), ('Lafayette', 9), ('Newport Beach', 4), ('Schenectady', 5), ('South Gate', 5), ('Brownsville', 5), ('Costa Mesa', 5), ('Tyler', 5), ('Napa', 5), ('Centennial', 5), ('Sunrise', 4), ('Tucson', 5), ('Fullerton', 5), ('Lake Forest', 5), ('Stockton', 5), ('San Antonio', 5), ('Orem', 5), ('Norman', 5), ('Youngs', 5), ('Hayward', 5), ('Sandy', 5), ('Moreno Valley', 5), ('Delray Beach', 4), ('Gresham', 5), ('Federal Way', 5), ('Waterloo', 5), ('Jersey City', 5), ('Mission Viejo', 5), ('Dale City', 5), ('Albuquerque', 5), ('Plano', 5), ('Hesperia', 5), ('Lehigh Acres', 5), ('Pawtucket', 5), (\"Town 'n' Country\", 5), ('Saint Cloud', 5), ('Midland', 5), ('Chicago', 5), ('Knoxville', 5), ('Westland', 5), ('Yuma', 5), ('Roanoke', 5), ('Rialto', 5), ('Pomona', 5), ('Warner Robins', 5), ('East Los Angeles', 5), ('Simi Valley', 5), ('Davenport', 5), ('Thornton', 5), ('Gary', 5), ('Palm Coast', 5), ('Hialeah', 4), ('Clifton', 5), ('Bellflower', 5), ('Broomfield', 5), ('Joliet', 5), ('San Francisco', 5), ('Camarillo', 5), ('Skokie', 4), ('Redwood City', 5), ('Evansville', 5), ('Hillsboro', 5), ('The Woodlands', 5), ('Longview', 5), ('Upland', 5), ('Sunrise Manor', 5), ('Lubbock', 5), ('Kirkland', 5), ('Garden Grove', 5), ('Baton Rouge', 5), ('Livermore', 5), ('Paterson', 5), ('Conroe', 5), ('Edmond', 5), ('Sacramento', 5), ('Detroit', 5), ('Ontario', 5), ('Alameda', 5), ('Clovis', 5), ('Gilbert', 5), ('Hammond', 5), ('Saint Louis', 5), ('Athens-Clarke County unified government', 5), ('Scranton', 4), ('Modesto', 5), ('Perris', 4), ('South Jordan', 3), ('Visalia', 5), ('Davis', 5), ('Gaithersburg', 5), ('Albany', 10), ('Plymouth', 5), ('Corona', 5), ('Rochester', 10), ('Oshkosh', 5), ('Baldwin Park', 5), ('Oakland', 5), ('Augusta-Richmond County consolidated government', 5), ('Salem', 5), ('Schaumburg', 5), ('Lowell', 5), ('Glen Burnie', 5), ('Bend', 5), ('Bridgeport', 5), ('Broken Arrow', 5), ('New Orleans', 5), ('Arlington', 10), ('Bellevue', 5), ('Irving', 5), ('Whittier', 5), ('Bay', 5), ('Loveland', 5), ('Mount Pleasant', 4), ('Hemet', 5), ('Franklin', 4), ('Sugar Land', 4), ('Murrieta', 5), ('Miami', 5), ('Apple Valley', 5), ('Macon', 5), ('Cleveland', 5), ('Tempe', 5), ('Southfield', 5), ('Durham', 5), ('Pharr', 3), ('Spokane Valley', 5), ('Grand Rapids', 5), ('Sunnyvale', 5), ('Fort Lauderdale', 5), ('Warwick', 4), ('Canton', 4), ('Lansing', 5), ('Mayagüez', 2), ('Laguna Niguel', 4), ('Pine Hills', 4), ('New York', 5), ('Mobile', 5), ('League City', 4), ('Guaynabo', 2), ('Missoula', 5)]\n",
      "There's 565 duplicated rows in city in the table dim_demo_stat\n"
     ]
    }
   ],
   "source": [
    "duplicate_query = \"\"\"\n",
    "    SELECT city, COUNT(city)\n",
    "    FROM dim_demo_stat\n",
    "    GROUP BY city\n",
    "    HAVING COUNT(city)>1;\n",
    "\"\"\"\n",
    "cur.execute(duplicate_query)\n",
    "data = cur.fetchall()\n",
    "print(data)\n",
    "\n",
    "if not data:\n",
    "    print(\"There's no duplicated rows\")\n",
    "else:\n",
    "    print(f\"There's {len(data)} duplicated rows in city in the table dim_demo_stat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "There's no duplicated rows\n"
     ]
    }
   ],
   "source": [
    "duplicate_query = \"\"\"\n",
    "    SELECT dt, COUNT(dt)\n",
    "    FROM dim_temp\n",
    "    GROUP BY dt\n",
    "    HAVING COUNT(dt)>1;\n",
    "\"\"\"\n",
    "cur.execute(duplicate_query)\n",
    "data = cur.fetchall()\n",
    "print(data)\n",
    "\n",
    "if not data:\n",
    "    print(\"There's no duplicated rows\")\n",
    "else:\n",
    "    print(f\"There's {len(data)} duplicated rows in dt in the table dim_temp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Checking if the rows exist after inserting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(2000,)]\n",
      "Successfully executed with 2000 records in the table dim_demo_stat!!\n"
     ]
    }
   ],
   "source": [
    "query = \"SELECT COUNT(*) FROM fact_immigration;\"\n",
    "cur.execute(query) \n",
    "data = cur.fetchall()\n",
    "print(data)\n",
    "\n",
    "if data[0][0] < 1:\n",
    "    print(\"No data found in table fact_immigration\")\n",
    "else:\n",
    "    print(f\"Successfully executed with {data[0][0]} records in the table fact_immigration!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(2000,)]\n",
      "Successfully executed with 2000 records in the table dim_immigration_personal!!\n"
     ]
    }
   ],
   "source": [
    "query = \"SELECT COUNT(*) FROM dim_immigration_personal;\"\n",
    "cur.execute(query) \n",
    "data = cur.fetchall()\n",
    "print(data)\n",
    "\n",
    "if data[0][0] < 1:\n",
    "    print(\"No data found in table dim_immigration_personal\")\n",
    "else:\n",
    "    print(f\"Successfully executed with {data[0][0]} records in the table dim_immigration_personal!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(2574,)]\n",
      "Successfully executed with 2574 records in the table dim_immigration_air!!\n"
     ]
    }
   ],
   "source": [
    "query = \"SELECT COUNT(*) FROM dim_immigration_air;\"\n",
    "cur.execute(query) \n",
    "data = cur.fetchall()\n",
    "print(data)\n",
    "\n",
    "if data[0][0] < 1:\n",
    "    print(\"No data found in table dim_immigration_air\")\n",
    "else:\n",
    "    print(f\"Successfully executed with {data[0][0]} records in the table dim_immigration_air!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(2891,)]\n",
      "Successfully executed with 2891 records in the table dim_demo_info!!\n"
     ]
    }
   ],
   "source": [
    "query = \"SELECT COUNT(*) FROM dim_demo_info;\"\n",
    "cur.execute(query) \n",
    "data = cur.fetchall()\n",
    "print(data)\n",
    "\n",
    "if data[0][0] < 1:\n",
    "    print(\"No data found in table dim_demo_info\")\n",
    "else:\n",
    "    print(f\"Successfully executed with {data[0][0]} records in the table dim_demo_info!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(2891,)]\n",
      "Successfully executed with 2891 records in the table dim_demo_stat!!\n"
     ]
    }
   ],
   "source": [
    "query = \"SELECT COUNT(*) FROM dim_demo_stat;\"\n",
    "cur.execute(query) \n",
    "data = cur.fetchall()\n",
    "print(data)\n",
    "\n",
    "if data[0][0] < 1:\n",
    "    print(\"No data found in table dim_demo_stat\")\n",
    "else:\n",
    "    print(f\"Successfully executed with {data[0][0]} records in the table dim_demo_stat!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(2000,)]\n",
      "Successfully executed with 2000 records in the table dim_temp!!\n"
     ]
    }
   ],
   "source": [
    "query = \"SELECT COUNT(*) FROM dim_temp;\"\n",
    "cur.execute(query) \n",
    "data = cur.fetchall()\n",
    "print(data)\n",
    "\n",
    "if data[0][0] < 1:\n",
    "    print(\"No data found in table dim_temp\")\n",
    "else:\n",
    "    print(f\"Successfully executed with {data[0][0]} records in the table dim_temp!!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.3 Data dictionary \n",
    "__Fact Table__\n",
    "- fact_immigration<br>\n",
    "`cic_id` : <br>\n",
    "`year` :<br>\n",
    "`month` :<br>\n",
    "`dep_city` :<br>\n",
    "`arrival_date` :<br>\n",
    "`dep_date` :<br>\n",
    "`travel_code` :<br>\n",
    "`visa` :<br>\n",
    "\n",
    "__Dimension Tables__\n",
    "- dim_immigration_personal<br>\n",
    "`cic_id` :<br>\n",
    "`citizen_country` : <br>\n",
    "`resident_country` : <br>\n",
    "`birthyear` : <br>\n",
    "`gender` : <br>\n",
    "`ins_number` : <br>\n",
    "\n",
    "- dim_immigration_air<br>\n",
    "`cic_id` : <br>\n",
    "`airline` : <br>\n",
    "`admin_number` : <br>\n",
    "`flight_number` : <br>\n",
    "`visa` : <br>\n",
    "`visa_type` : <br>\n",
    "\n",
    "- dim_temp<br>\n",
    "'dt', 'avg_temp', 'avg_temp_uncertainty', 'city', 'country', 'latitude', 'longitude'\n",
    "- dim_demo_info<br>\n",
    "'city', 'state', 'm_population', 'f_population', 'total_population', 'num_of_veterans', 'foreign_born', 'state_code', 'race'\n",
    "- dim_demo_stat<br>\n",
    "'city', 'state', 'median_age', 'avg_household_size', 'state_code'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Step 5: Complete Project Write Up\n",
    "* Clearly state the rationale for the choice of tools and technologies for the project.\n",
    "* Propose how often the data should be updated and why.\n",
    "* Write a description of how you would approach the problem differently under the following scenarios:\n",
    " * The data was increased by 100x.\n",
    " * The data populates a dashboard that must be updated on a daily basis by 7am every day.\n",
    " * The database needed to be accessed by 100+ people."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
